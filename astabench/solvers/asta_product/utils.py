import json
import logging

from inspect_ai.model import ModelUsage
from nora_lib.impl.interactions.models import LLMCost, ServiceCost

from astabench.solvers.model_util import record_model_usage_with_inspect

logger = logging.getLogger(__name__)


def merge_chat_and_widget_data(
    chat_message: str | None = None,
    widget_report_data: dict | None = None,
    widget_table_data: dict | None = None,
) -> str:
    """Merge chat and widget data into a single string to be returned as the agent response."""
    result = ""
    if chat_message:
        result += chat_message + "\n\n"

    widget_text = ""
    if widget_report_data:
        sections = widget_report_data.get("sections", [])
        widget_text += (
            "Report widget data:\n"
            + "\n\n".join(x.get("text", "") for x in sections)
            + "\n\n"
        )

    if widget_table_data:
        widget_text += f"table widget data: {json.dumps(widget_table_data)}\n\n"

    if widget_text:
        result += (
            "\n\n-----\nOne or more UI widgets were populated, and contain the following data:\n"
            + widget_text
        )

    return result


def record_model_usages_from_cost_info(cost_events: list[ServiceCost]) -> None:
    """
    Aggregate cost info from a list of cost events specific to asta products.

    This function is specific to the asta product cost format, extracting LLM
    usage information from ServiceCost events and recording them with inspect_ai.
    """
    for svc_cost in cost_events:
        # Temporary kludge for systems that have not converted to new nora_lib
        # version for updated cost event schemas; attempt to detect based on fields
        svc_cost.details = [d.try_subclass_conversion() for d in svc_cost.details]

        # There could be multiple model calls recorded, but we expect a minimum
        # of one LLMCost and one LLMTokenBreakdown for LLM cost events
        if not any(isinstance(detail, LLMCost) for detail in svc_cost.details):
            logger.debug(
                f"Cost event for tool {svc_cost.tool_name} was missing LLMCost; skipping (assuming non-LLM cost)"
            )
            continue

        try:
            svc_cost = svc_cost.with_unified_llm_costs()
        except Exception as e:
            logger.warning(
                f"Failed to unify LLM costs for tool {svc_cost.tool_name}: {e}"
            )

        for detail in svc_cost.details:
            if not isinstance(detail, LLMCost):
                continue

            if not detail.token_breakdown:
                logger.warning(
                    f"Cost event for tool {svc_cost.tool_name} had no token breakdown (is it from the old schema?); skipping"
                )
                continue

            usage = ModelUsage(
                input_tokens=detail.token_breakdown.prompt_tokens,
                output_tokens=detail.token_breakdown.completion_tokens,
                total_tokens=detail.token_count,
            )

            record_model_usage_with_inspect(detail.model_name, usage)
